# -*- coding: utf-8 -*-
"""DepMedObs

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DQPpH1nuHKpstJK2WeIDlBczOElW7Elx

## **Camera Trap Data Package Functionality**

1. Import the required libraries.
2. Setting path for envVars.csv using glob()
3. Setting path for metaData_....csv using glob()
4. Setting path for modelResults_....csvusing glob()
5. Create a parent data table to pick \& pull columns from.
6. Append \& rename columns that are missing or incorrectly named.
7. Create deployments csv data table and saving to working directory using .to_csv( )
8. Create media csv data table using .loc[ ].
9. Create observations csv data table using .loc[ ]

###1. Import the required libraries.

When we import modules we're able to call functions that are not built into Python. Some modules are installed as part of Python, and some we will install through pip . Making use of modules allows us to make our programs more robust and powerful as we're leveraging existing code.
"""

import glob, os, json, datetime
import pandas as pd
from re import search

"""###2. Setting path for envVars.csv using glob()

Glob is a general term used to define techniques to match specified patterns according to rules related to Unix shell. Linux and Unix systems and shells also support glob and also provide function glob() in system libraries.

In Python, the glob module is used to retrieve files/pathnames matching a specified pattern. The pattern rules of glob follow standard Unix path expansion rules. It is also predicted that according to benchmarks it is faster than other methods to match pathnames in directories. With glob, we can also use wildcards ("*, ?, [ranges]) apart from exact string search to make path retrieval more simple and convenient.

---


"""

#listing is an array of possiuble file paths
listing = glob.glob("/Volumes/**/DCIM/envVars.csv") #using wild card to find the specific file names envVars.csv that is in the DCIM1 folder
for name in listing:
  PosFilPath = input("does this file path look correct? \n" + name + "\n Look for envVars.csv within the DCIM parent directory of the SD card and confirm this file path. \n").lower()
  if PosFilPath.startswith('y') == True:   # etc.
    envVars = pd.read_csv(name, sep = "=") #customo delimeter "=" rather than normal ',' 
    fileName = envVars.loc[envVars.Variables=="fileNamesMeta"].Values #extracting csv file name that will be convension for the rest of the files created 
    PosFilPath = "y"
    break

    
while PosFilPath.startswith('y') == False:
  name = input("Input path to csv file named envVars.csv: \n")
  PosFilPath = input("Does this look correct? " + name + "\n")

  if PosFilPath.startswith('y') == True: 

    envVarsExist = os.path.exists(name)
    #print(envVarsExist)

    if envVarsExist != False:
      if search("envVars", name):
        print("That seems to be the right file name.\n")
      else:
        print("This is a file path but that doesn't seeem to be the right file name.\nFile should be named metaData.....csv and should be within DCIM folder on SD card")
        PosFilPath = "no"
    else: 
      print("The file " + name + " is an invalid file path, try again\n")
      PosFilPath = "no"

  
envVars = pd.read_csv(name, sep = "=")  
fileName = envVars.loc[envVars.Variables=="fileNamesMeta"].Values[2]

#getting general parent directory. 
readLocation = envVars.loc[envVars.Variables=="read_location"].Values[0] #parent directory of

"""###3. Setting path for metaData_....csv using glob()

Glob is a general term used to define techniques to match specified patterns according to rules related to Unix shell. Linux and Unix systems and shells also support glob and also provide function glob() in system libraries.

In Python, the glob module is used to retrieve files/pathnames matching a specified pattern. The pattern rules of glob follow standard Unix path expansion rules. It is also predicted that according to benchmarks it is faster than other methods to match pathnames in directories. With glob, we can also use wildcards ("*, ?, [ranges]) apart from exact string search to make path retrieval more simple and convenient.
"""

#finding metadata...csv file
#this is gettin possibel file path for metaData....csv file
listing = glob.glob("/content" + readLocation + "/metaData*") #using wild card to find the specific file names metaData....csv that is in the DCIM folder
for name in listing:
  PosFilPath = input("Look for metaData....csv within the DCIM parent directory of the SD card and confirm that file path is correct: \n" + name + "\n").lower()
  if PosFilPath.startswith('y') == True:   # etc.
    data = pd.read_csv(name) 
    PosFilPath = "y"
    break


while PosFilPath.startswith('y') == False:
  name = input("Input path to metaData....csv:\n")
  PosFilPath = input("Does this look correct? " + name + "(yes/no) \n") 

  if PosFilPath.startswith('y') == True: 
    
    metadataPathExist = os.path.exists(name)

    #print(modelPathExist)
    if metadataPathExist != False:
      if search("metaData", name):
        print("That seems to be the right file name.\n")
      else:
        print("This is a file path but that doesn't seeem to be the right file name.\nFile should be named metaData.....csv and should be within DCIM folder on SD card")
        PosFilPath = "no"
    else: 
      print("The file " + name + " is an invalid file path, try again\n")
      PosFilPath = "no"

data = pd.read_csv(name)

"""###4. Setting path for modelResults_....csvusing glob()

Glob is a general term used to define techniques to match specified patterns according to rules related to Unix shell. Linux and Unix systems and shells also support glob and also provide function glob() in system libraries.

In Python, the glob module is used to retrieve files/pathnames matching a specified pattern. The pattern rules of glob follow standard Unix path expansion rules. It is also predicted that according to benchmarks it is faster than other methods to match pathnames in directories. With glob, we can also use wildcards ("*, ?, [ranges]) apart from exact string search to make path retrieval more simple and convenient.
"""

#finding modelResults...csv files
listing = glob.glob("/content" + readLocation + "/modelResults_*") #using wild card to find the specific file names metaData....csv that is in the DCIM folder

for name in listing:
  PosFilPath = input("Look for modelResults....csv within the DCIM parent directory of the SD card and confirm that file path is correct: \n" + name + "\n").lower()
  if PosFilPath.startswith('y') == True:   # etc.
    data = pd.read_csv(name) 
    PosFilPath = "y"
    break

while PosFilPath.startswith('y') == False:
  name = input("Input path to metaData....csv within the DCIM parent directory of the SD card and confirm that file path is correct:\n")
  PosFilPath = input("Does this look correct? " + name + " (yes/no) \n")

  if PosFilPath.startswith('y') == True: 

    modelPathExist = os.path.exists(name)

    #print(modelPathExist)
    if modelPathExist != False:
      if search("modelResults_", name):
        print("That seems to be the right file name.\n")
      else:
        print("This is a file path but that doesn't seeem to be the right file name.\nFile should be named modelResults_.....csv and should be within DCIM folder on SD card")
        PosFilPath = "no"
    else: 
      print("The file " + name + " is an invalid file path, try again\n")
      PosFilPath = "no"

modelData = pd.read_csv(name)

"""###5. Create a parent data table to pick \& pull columns from.

This is the most common type of join. Inner joins combine records from two tables whenever there are matching values in a field common to both tables.
"""

parentTable = pd.merge(modelData, data,
                       how='inner', 
                       on='fileName')
#Join data. Retain only rows in both sets.
parentTable.head()

"""###6. Append \& rename columns that are missing or incorrectly named.

* The append operation creates a single table by adding the contents of one or more tables to another, and aggregates the column headers from the tables to create the schema for the new table.

"""

noInParent = ["observationID",
"deploymentID",
"sequenceID",
"mediaID",
"mediaID", 
"cameraSetup",
"taxonID",
"scientificName",
"count",
"countNew", 
"lifeStage",
"behaviour", 
"sex",
"individualID",
"comments"]

for name in noInParent:
  yesno = pd.Series([name]).isin(parentTable.columns).all()
  if yesno == False:
    parentTable[name] = pd.Series(["" for x in range(len(parentTable.index))])

parentTable['index'] = range(1, len(parentTable) + 1)

parentTable["prefix"] = pd.Series([(fileName)  for x in range(len(parentTable.index))])

parentTable["sequenceID"] = parentTable.prefix +  "_SEQ_" +  parentTable.index.astype(str)

parentTable['captureMethod'] = pd.Series(["Motion detection" for x in range(len(parentTable.index))])

parentTable["observationID"] =  (parentTable.FileName.str.split(".")).str[0] + "_obs1"

parentTable["deploymentID"] = pd.Series([(deploymentID)  for x in range(len(parentTable.index))])

parentTable["_id"] = pd.Series([""  for x in range(len(parentTable.index))])

exifList = []
for i in data.index:
    exifList.append(data.loc[i].to_json( orient = "split"))

parentTable['exifData'] = exifList

parentTable["favourite"] = pd.Series([""  for x in range(len(parentTable.index))])

parentTable["mediaID"] = parentTable.FileName.str.split(".").str[0]

parentTable['classifiedBy'] = pd.Series(["efficientnet_lite3" for x in range(len(parentTable.index))])

parentTable.rename(columns = {"DateTimeOriginal" : "timestamp", 
                                "SourceFile": "filePath",
                                "FileName" : "fileName",
                                "MIMEType": "fileMediatype"}, inplace = True)

"""###7. Create deployments csv data table and saving to working directory using .to_csv( )

Pandas DataFrame to_csv() function converts DataFrame into CSV data. If a file argument is provided, the output is written to the file. Otherwise, CSV
string is returned. We can specify custom delimiter for the CSV output, default is a comma.
"""

#ask for camera_loc & cam_postion 

#set up as independent varibles 
cameraID = (input("Please enter Camera ID: ")).upper()
yesNo = input("Does this look correct? " + cameraID  + "\n")

while yesNo.lower() != "yes":
  cameraID = (input("Please enter Camera ID: ")).upper()
  yesNo = input("Does this look correct? " + cameraID + "\n")


cameraLoc = (input("Please enter Camera Loc. Name: ")).upper()
yesNo = input("Does this look correct? " + cameraLoc  + "\n")


while yesNo.lower() != "yes":
  cameraLoc = (input("Please enter Camera Loc. Name: ")).upper()
  yesNo = input("Does this look correct? " + cameraLoc + "\n")

#deploymentID -> cameraID+cameraLoc

deploymentID = cameraLoc + "_" + cameraID

#locationID -> cameraID

locationID = cameraID

#locationName -> cameraLoc
locationName = cameraLoc

#longitude -> should be float with 5 decimal places 
  #example: 52.70442 -> [52, 70442]

longitude = float(input("Please enter longitude with 5 decimal place accuracy: "))
while (len(str(longitude).split(".")[1]) != 5):
  longitude = float(input("Please enter longitude with 5 decimal place accuracy: "))


#latitude -> should be float with 5 decimal places 
  #example: 52.70442

latitude = float(input("Please enter latitude with 5 decimal place accuracy: "))
while (len(str(latitude).split(".")[1]) != 5):
  latitude = float(input("Please enter latitude with 5 decimal place accuracy: "))

#start -> date of oldest picture in csv file
start = parentTable.sort_values(by=["DateTimeOriginal"]).DateTimeOriginal[0]

#end -> date of newest picture in csv file
end = parentTable.sort_values(by=["DateTimeOriginal"]).iloc[-1].DateTimeOriginal


#cameraID ->  df['A'].unique()
cameraID =  cameraID

#cameraModel -> data.model.unique() #should be a single value since its all the same camera
cameraModel = parentTable[~parentTable['Model'].isnull()].Model.unique()[0]



setupBy = input("Who set up this camera, enter in following format: FIRST LAST\n").upper()
nameCheck = input("does this name look correct " + setupBy + " (yes/no): \n").lower()
if nameCheck.startswith('y') == True:   # etc.
  setupBy = setupBy 
  PosFilPath = "y"

while nameCheck.startswith('y') == False:
  setupBy = input("Who set up this camera, enter in following format: FIRST LAST\n").upper()
  nameCheck = input("does this name look correct " + setupBy + " (yes/no): \n").lower

def checkNum(num):
  try:
      string_int = int(num)
      return True
  except ValueError:
      # Handle the exception
      return False


timestampIssues = input("Did this camera have any time stamp issues? Yes = 1 and No = 0 (0/1) \n")
issueCheck = input("does this name look correct " + timestampIssues + " (yes/no): \n").lower()
checkNum(issueCheck)
while checkNum(timestampIssues) != True:
  timestampIssues = input("Did this camera have any time stamp issues? \nResponce must be 1/0 -> Yes = 1 and No = 0 \n")
  issueCheck = input("does this name look correct " + timestampIssues + " (yes/no): \n").lower()
  checkNum(issueCheck)

#save this as deployments+name of exifdata (without extension) +.csv
  #example: deployments_2022_UCSB11_11A_02.csv



#creating dictionary with appropriate structure
deploymentContent = {"deploymentID" : [deploymentID],
                     "locationID" : [locationID], 
                     "locationName" : [locationName], 
                     "longitude" : [longitude], 
                     "latitude" : [latitude],
                     "coordinateUncertainty": [""], 
                     "start" : [start],
                     "end" : [end],
                     "setupBy": [setupBy],
                     "cameraID" : [cameraID], 
                     "cameraModel" : [cameraModel],
                     "cameraInterval" : [""],
                     "cameraHeight" : [""],
                     "cameraTilt" : [""],
                     "cameraHeading" : [""],
                     "detectionDistance" : [""],
                     "timestampIssues": [timestampIssues],
                     "baitUsed" : ["None"],
                     "session": [""],
                     "array": [""],
                     "featureType": [""],
                     "habitat" : [""],
                     "tags": [""],
                     "comments" : [""],
                     "_id" : [""]}

"""####Creating deployments...csv file and saving to working directory using .to_csv( ) 

Pandas DataFrame to_csv() function converts DataFrame into CSV data. If a file argument is provided, the output is written to the file. Otherwise, CSV
string is returned. We can specify custom delimiter for the CSV output, default is a comma.
"""

csvName = "deployments_" + str(fileName) + ".csv"

deploymentPD = pd.DataFrame.from_dict(deploymentContent)

deploymentPD.to_csv(csvName, sep=',', index=False)

print("Deployments file for this camera has been created and saved in the current working directory under '" + csvName + "'")

"""###8. Create media csv data table using .loc[ ]

The loc operator is used to index a portion of the dataframe. loc supports indexing both by row and column names and by using boolean expressions.


"""

yesNo = input("Any Extra comments that you would like to add; you would want to enter field note comments here: ")

if yesNo.lower() != "no":
  comments = input("input comment: ")
  print(comments)
  correct = input("does this look correct (Yes/No)? ")
  while correct.lower() != "yes":
    comments = input("input comment: ")
    print(comments)
    correct = input("does this look correct (Yes/No)? ")
else: 
  comments = ""


mediaContent = parentTable.loc[:,["mediaID", 
                                "deploymentID",
                                "sequenceID", 
                                "captureMethod",
                                "timestamp", 
                                "filePath",
                                "fileName",
                                "fileMediatype",
                                "exifData",
                                "favourite",
                                "_id"]]

mediaContent["comments"] = pd.Series([(comments)  for x in range(len(parentTable.index))])

"""####Reording Data Frame to fit Camera Trap DP standards"""

#reording dataframe 

order = ["mediaID", "deploymentID", "sequenceID", "captureMethod", "timestamp", "filePath", "fileName", "fileMediatype", "exifData", "favourite", "comments", "_id"]

mediaContent = mediaContent[order]

"""####Creating media...csv file and saving to working directory using .to_csv( ) 

Pandas DataFrame to_csv() function converts DataFrame into CSV data. If a file argument is provided, the output is written to the file. Otherwise, CSV
string is returned. We can specify custom delimiter for the CSV output, default is a comma.
"""

csvName = "media_" + str(fileName) + ".csv"

#csvName
mediaContent.to_csv(csvName, sep=',', index=False)

print("Media file for this camera has been created and saved in the current working directory under'" + csvName + "'")

"""###9. Create observations csv data table using .loc[ ] 

The loc operator is used to index a portion of the dataframe. loc supports indexing both by row and column names and by using boolean expressions.
"""

observationContent = parentTable.loc[:,["observationID",
                                        "deploymentID", 
                                        "sequenceID", 
                                        "mediaID", 
                                        "timestamp",
                                        "observationType",
                                        "cameraSetup", 
                                        "taxonID", 
                                        "scientificName", 
                                        "count", 
                                        "countNew", 
                                        "lifeStage", 
                                        "lifeStage", 
                                        "sex", 
                                        "behaviour", 
                                        "individualID",
                                        "classificationMethod",
                                        "classifiedBy",
                                        "classificationTimestamp",
                                        "classificationConfidence",
                                        "comments", 
                                        "_id"]]

"""####Creating observations...csv file and saving to working directory using .to_csv( )

Pandas DataFrame to_csv() function converts DataFrame into CSV data. If a file argument is provided, the output is written to the file. Otherwise, CSV
string is returned. We can specify custom delimiter for the CSV output, default is a comma.
"""

csvName = "observations_" + str(fileName) + ".csv"

observationContentPD = pd.DataFrame.from_dict(observationContent)

observationContentPD.to_csv(csvName, sep=',', index=False)

print("Observations file for this camera has been created and saved in the current working directory under '" + csvName + "'")
